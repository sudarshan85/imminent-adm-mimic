{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First ICU & 5 Day Discharge Prediction using Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T11:47:46.292623Z",
     "start_time": "2019-06-28T11:47:46.279401Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T11:47:48.453446Z",
     "start_time": "2019-06-28T11:47:46.293983Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import interp, stats\n",
    "import lightgbm\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "from utils.splits import set_two_splits\n",
    "from utils.metrics import BinaryAvgMetrics, get_best_model\n",
    "from utils.plots import *\n",
    "from args import args\n",
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T11:47:50.099782Z",
     "start_time": "2019-06-28T11:47:48.455153Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "ori_df = pd.read_csv(args.dataset_csv, usecols=args.cols)\n",
    "\n",
    "imminent_df = ori_df.loc[(ori_df['imminent_label'] != -1)][['scispacy_note', 'imminent_label']].reset_index()\n",
    "discharge_df = ori_df[['scispacy_note', 'discharge_label']].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imminent ICU Admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T11:47:59.647797Z",
     "start_time": "2019-06-28T11:47:53.204751Z"
    }
   },
   "outputs": [],
   "source": [
    "df = set_two_splits(imminent_df.copy(), 'test', seed=seed)\n",
    "vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, sublinear_tf=True, ngram_range=(2,2))\n",
    "x_train = vectorizer.fit_transform(df.loc[(df['split'] == 'train')]['scispacy_note'])\n",
    "x_test = vectorizer.transform(df.loc[(df['split'] == 'test')]['scispacy_note'])\n",
    "y_train = df.loc[(df['split'] == 'train')]['imminent_label'].to_numpy()\n",
    "y_test = df.loc[(df['split'] == 'test')]['imminent_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T11:47:59.700711Z",
     "start_time": "2019-06-28T11:47:59.651213Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 50,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0,\n",
    "    'num_threads': 32,\n",
    "    'min_data_in_leaf': 3,\n",
    "    'num_iterations': 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T11:49:33.139447Z",
     "start_time": "2019-06-28T11:47:59.702756Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = lightgbm.LGBMClassifier(**parameters)\n",
    "clf.fit(x_train, y_train)\n",
    "prob = clf.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T11:49:34.024738Z",
     "start_time": "2019-06-28T11:49:33.141867Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plot_thresh_range(ax, y_test, prob, 0.3, 0.7, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T11:49:34.069356Z",
     "start_time": "2019-06-28T11:49:34.026172Z"
    }
   },
   "outputs": [],
   "source": [
    "args.imminent_threshold = 0.3\n",
    "y_pred = (prob > args.imminent_threshold).astype(np.int64)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn,fp,fn,tp = cm[0][0],cm[0][1],cm[1][0],cm[1][1]\n",
    "prevalence = (fn+tp)/(tn+fp+fn+tp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "ppv = tp/(tp+fp)\n",
    "npv = tn/(tn+fn)\n",
    "f1 = (2*ppv*sensitivity)/(ppv+sensitivity)\n",
    "auroc = roc_auc_score(y_test, prob)\n",
    "\n",
    "d = {\n",
    "  'sensitivity': np.round(sensitivity, 3),\n",
    "  'specificity': np.round(specificity, 3),\n",
    "  'ppv': np.round(ppv, 3),\n",
    "  'npv': np.round(npv, 3),\n",
    "  'f1': np.round(f1, 3),\n",
    "  'auroc': np.round(auroc, 3),\n",
    "  'prevalence': np.round(prevalence, 3),  \n",
    "}\n",
    "\n",
    "metrics = pd.DataFrame(d.values(), index=d.keys(), columns=['Value'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T12:37:02.542132Z",
     "start_time": "2019-06-28T12:37:01.969687Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "neg_cloud, pos_cloud = get_wordcloud(vectorizer.get_feature_names(), clf.feature_importances_, n_words=50)\n",
    "ax[0].imshow(neg_cloud)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Negative Class')\n",
    "ax[1].imshow(pos_cloud)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Positive Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICU Discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = set_two_splits(discharge_df.copy(), 'test', seed=seed)\n",
    "vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, sublinear_tf=True, ngram_range=(2,2))\n",
    "x_train = vectorizer.fit_transform(df.loc[(df['split'] == 'train')]['scispacy_note'])\n",
    "x_test = vectorizer.transform(df.loc[(df['split'] == 'test')]['scispacy_note'])\n",
    "y_train = df.loc[(df['split'] == 'train')]['discharge_label'].to_numpy()\n",
    "y_test = df.loc[(df['split'] == 'test')]['discharge_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T12:37:49.678140Z",
     "start_time": "2019-06-28T12:37:49.467965Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 50,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0,\n",
    "    'num_threads': 32,\n",
    "    'min_data_in_leaf': 3,\n",
    "    'num_iterations': 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T12:39:26.604112Z",
     "start_time": "2019-06-28T12:37:52.101559Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = lightgbm.LGBMClassifier(**parameters)\n",
    "clf.fit(x_train, y_train)\n",
    "prob = clf.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T12:39:27.608240Z",
     "start_time": "2019-06-28T12:39:26.606861Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plot_thresh_range(ax, y_test, prob, 0.3, 0.7, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T12:43:26.931889Z",
     "start_time": "2019-06-28T12:43:26.889286Z"
    }
   },
   "outputs": [],
   "source": [
    "args.discharge_threshold = 0.3\n",
    "y_pred = (prob > args.discharge_threshold).astype(np.int64)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn,fp,fn,tp = cm[0][0],cm[0][1],cm[1][0],cm[1][1]\n",
    "prevalence = (fn+tp)/(tn+fp+fn+tp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "ppv = tp/(tp+fp)\n",
    "npv = tn/(tn+fn)\n",
    "f1 = (2*ppv*sensitivity)/(ppv+sensitivity)\n",
    "auroc = roc_auc_score(y_test, prob)\n",
    "\n",
    "d = {\n",
    "  'sensitivity': np.round(sensitivity, 3),\n",
    "  'specificity': np.round(specificity, 3),\n",
    "  'ppv': np.round(ppv, 3),\n",
    "  'npv': np.round(npv, 3),\n",
    "  'f1': np.round(f1, 3),\n",
    "  'auroc': np.round(auroc, 3),\n",
    "  'prevalence': np.round(prevalence, 3),  \n",
    "}\n",
    "\n",
    "metrics = pd.DataFrame(d.values(), index=d.keys(), columns=['Value'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T12:43:11.163325Z",
     "start_time": "2019-06-28T12:43:10.566161Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "neg_cloud, pos_cloud = get_wordcloud(vectorizer.get_feature_names(), clf.feature_importances_/clf.feature_importances_.sum(), n_words=50)\n",
    "ax[0].imshow(neg_cloud)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Negative Class')\n",
    "ax[1].imshow(pos_cloud)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Positive Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T17:05:40.456597Z",
     "start_time": "2019-06-13T17:05:32.697528Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "ori_df = pd.read_csv(args.dataset_csv, usecols=args.cols)\n",
    "df = set_two_splits(ori_df.copy(), 'test', seed=seed)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, sublinear_tf=True,\\\n",
    "                              ngram_range=(2,2))\n",
    "x_train = vectorizer.fit_transform(df.loc[(df['split'] == 'train')]['scispacy_note'])\n",
    "x_test = vectorizer.transform(df.loc[(df['split'] == 'test')]['scispacy_note'])\n",
    "y_train = df.loc[(df['split'] == 'train')]['class_label'].to_numpy()\n",
    "y_test = df.loc[(df['split'] == 'test')]['class_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T17:07:05.817492Z",
     "start_time": "2019-06-13T17:05:40.463391Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 50,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0,\n",
    "    'num_threads': 32,\n",
    "    'min_data_in_leaf': 3,\n",
    "    'num_iterations': 1000,\n",
    "}\n",
    "\n",
    "clf = lightgbm.LGBMClassifier(**parameters)\n",
    "clf.fit(x_train, y_train)\n",
    "prob = clf.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T17:07:06.769256Z",
     "start_time": "2019-06-13T17:07:05.821025Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plot_thresh_range(ax, y_test, prob, 0.3, 0.7, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T17:07:06.807947Z",
     "start_time": "2019-06-13T17:07:06.770608Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = (prob > 0.3).astype(np.int64)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn,fp,fn,tp = cm[0][0],cm[0][1],cm[1][0],cm[1][1]\n",
    "prevalence = (fn+tp)/(tn+fp+fn+tp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "ppv = tp/(tp+fp)\n",
    "npv = tn/(tn+fn)\n",
    "f1 = (2*ppv*sensitivity)/(ppv+sensitivity)\n",
    "auroc = roc_auc_score(y_test, prob)\n",
    "\n",
    "d = {\n",
    "  'sensitivity': np.round(sensitivity, 3),\n",
    "  'specificity': np.round(specificity, 3),\n",
    "  'ppv': np.round(ppv, 3),\n",
    "  'npv': np.round(npv, 3),\n",
    "  'f1': np.round(f1, 3),\n",
    "  'auroc': np.round(auroc, 3),\n",
    "  'prevalence': np.round(prevalence, 3),  \n",
    "}\n",
    "\n",
    "metrics = pd.DataFrame(d.values(), index=d.keys(), columns=['Value'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T17:07:07.145290Z",
     "start_time": "2019-06-13T17:07:06.809163Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "plot_confusion_matrix(ax[0], cm, classes=['not imminent', 'imminent'], normalize=False, title='Confusion matrix')\n",
    "plot_confusion_matrix(ax[1], cm, classes=['not imminent', 'imminent'], normalize=True,\\\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 100 Seed Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T17:07:07.168800Z",
     "start_time": "2019-06-13T17:07:07.146685Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 50,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0,\n",
    "    'num_threads': 32,\n",
    "    'min_data_in_leaf': 3,\n",
    "    'num_iterations': 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:40:24.684979Z",
     "start_time": "2019-06-13T17:07:07.170701Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ori_df = pd.read_csv(args.dataset_csv, usecols=args.cols)\n",
    "preds = []\n",
    "targs = []\n",
    "probs = []\n",
    "\n",
    "for seed in range(args.start_seed, args.start_seed + 100):\n",
    "  if seed % 10 == 0:\n",
    "    print(f\"Running classifier with seed {seed}\")\n",
    "  df = set_two_splits(ori_df.copy(), 'test', seed=seed)\n",
    "  vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, ngram_range=(2,2))\n",
    "  \n",
    "  x_train = vectorizer.fit_transform(df.loc[(df['split'] == 'train')]['scispacy_note'])\n",
    "  x_test = vectorizer.transform(df.loc[(df['split'] == 'test')]['scispacy_note'])\n",
    "  \n",
    "  y_train = df.loc[(df['split'] == 'train')]['class_label'].to_numpy()\n",
    "  y_test = df.loc[(df['split'] == 'test')]['class_label'].to_numpy()\n",
    "  targs.append(y_test)\n",
    "  \n",
    "  clf = lightgbm.LGBMClassifier(**parameters)\n",
    "  \n",
    "  clf.fit(x_train, y_train)  \n",
    "  pickle.dump(clf, open(args.modeldir/f'gbm_seed_{seed}.pkl', 'wb'))\n",
    "  \n",
    "  prob = clf.predict_proba(x_test)[:, 1]\n",
    "  probs.append(prob)\n",
    "  \n",
    "  y_pred = (prob > args.bc_threshold).astype(np.int64)\n",
    "  preds.append(y_pred)\n",
    "\n",
    "with open(args.workdir/f'preds.pkl', 'wb') as f:\n",
    "  pickle.dump(targs, f)\n",
    "  pickle.dump(preds, f)\n",
    "  pickle.dump(probs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:49:48.858227Z",
     "start_time": "2019-06-13T19:49:48.744745Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(args.workdir/f'preds.pkl', 'rb') as f:\n",
    "  targs = pickle.load(f)\n",
    "  preds = pickle.load(f)\n",
    "  probs = pickle.load(f)\n",
    "\n",
    "fnames = [f'gbm_seed_{seed}.pkl' for seed in range(args.start_seed, args.start_seed + 100)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:49:55.344475Z",
     "start_time": "2019-06-13T19:49:54.866550Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bam = BinaryAvgMetrics(targs, preds, probs)\n",
    "bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:50:01.185719Z",
     "start_time": "2019-06-13T19:50:00.966426Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bam.get_avg_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:50:07.086096Z",
     "start_time": "2019-06-13T19:50:07.007042Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bam.get_avg_metrics(conf=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:50:13.985605Z",
     "start_time": "2019-06-13T19:50:13.764278Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_best_model(bam, fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:50:25.932771Z",
     "start_time": "2019-06-13T19:50:25.166203Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "plot_mean_roc(ax, bam.targs, bam.probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:50:33.489770Z",
     "start_time": "2019-06-13T19:50:33.200440Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "plot_confusion_matrix(ax[0], bam.cm_avg, classes=['not imminent', 'imminent'], normalize=False,\\\n",
    "                      title='Confusion Matrix Over Runs')\n",
    "plot_confusion_matrix(ax[1], bam.cm_avg, classes=['not imminent', 'imminent'], normalize=True,\\\n",
    "                      title='Normalized Confusion Matrix Over Runs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:55:57.281770Z",
     "start_time": "2019-06-13T19:55:57.136763Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 50,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0,\n",
    "    'num_threads': 32,\n",
    "    'min_data_in_leaf': 3,\n",
    "    'num_iterations': 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:57:46.316883Z",
     "start_time": "2019-06-13T19:55:58.530600Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(args.dataset_csv, usecols=args.cols)\n",
    "vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, sublinear_tf=True,\\\n",
    "                              ngram_range=(2,2))\n",
    "\n",
    "x = vectorizer.fit_transform(df['scispacy_note'])\n",
    "y = df['class_label'].to_numpy()\n",
    "\n",
    "clf = lightgbm.LGBMClassifier(**parameters)\n",
    "clf.fit(x, y)\n",
    "df['prob'] = clf.predict_proba(x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:57:52.969280Z",
     "start_time": "2019-06-13T19:57:52.522930Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(args.workdir/'all_data_model.pkl', 'wb') as f:\n",
    "  pickle.dump(clf, f)\n",
    "  pickle.dump(vectorizer.vocabulary_, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
