{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First ICU & 5 Day Discharge Prediction using Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T12:47:20.846476Z",
     "start_time": "2019-06-28T12:47:20.833881Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T12:47:22.184886Z",
     "start_time": "2019-06-28T12:47:20.847988Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import interp, stats\n",
    "import lightgbm\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "from utils.splits import set_two_splits\n",
    "from utils.metrics import BinaryAvgMetrics, get_best_model\n",
    "from utils.plots import *\n",
    "from args import args\n",
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T12:47:23.895734Z",
     "start_time": "2019-06-28T12:47:22.186453Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "ori_df = pd.read_csv(args.dataset_csv, usecols=args.cols)\n",
    "\n",
    "imminent_df = ori_df.loc[(ori_df['imminent_label'] != -1)][['scispacy_note', 'imminent_label']].reset_index()\n",
    "discharge_df = ori_df[['scispacy_note', 'discharge_label']].reset_index()\n",
    "\n",
    "print(imminent_df.shape)\n",
    "print(discharge_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imminent ICU Admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T12:48:18.427849Z",
     "start_time": "2019-06-28T12:48:11.289669Z"
    }
   },
   "outputs": [],
   "source": [
    "df = set_two_splits(imminent_df.copy(), 'test', seed=seed)\n",
    "vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, sublinear_tf=True, ngram_range=(2,2))\n",
    "x_train = vectorizer.fit_transform(df.loc[(df['split'] == 'train')]['scispacy_note'])\n",
    "x_test = vectorizer.transform(df.loc[(df['split'] == 'test')]['scispacy_note'])\n",
    "y_train = df.loc[(df['split'] == 'train')]['imminent_label'].to_numpy()\n",
    "y_test = df.loc[(df['split'] == 'test')]['imminent_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T12:48:18.593668Z",
     "start_time": "2019-06-28T12:48:18.430234Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape, x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T12:52:41.520755Z",
     "start_time": "2019-06-28T12:49:03.095008Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 50,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0,\n",
    "    'num_threads': 32,\n",
    "    'min_data_in_leaf': 3,\n",
    "    'num_iterations': 1000,\n",
    "}\n",
    "\n",
    "clf = lightgbm.LGBMClassifier(**parameters)\n",
    "clf.fit(x_train, y_train)\n",
    "prob = clf.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:29:27.166137Z",
     "start_time": "2019-06-28T14:29:25.652203Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plot_thresh_range(ax, y_test, prob, 0.3, 0.7, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:31:44.063690Z",
     "start_time": "2019-06-28T14:31:43.635200Z"
    }
   },
   "outputs": [],
   "source": [
    "args.imminent_threshold = 0.3\n",
    "y_pred = (prob > args.imminent_threshold).astype(np.int64)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn,fp,fn,tp = cm[0][0],cm[0][1],cm[1][0],cm[1][1]\n",
    "prevalence = (fn+tp)/(tn+fp+fn+tp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "ppv = tp/(tp+fp)\n",
    "npv = tn/(tn+fn)\n",
    "f1 = (2*ppv*sensitivity)/(ppv+sensitivity)\n",
    "auroc = roc_auc_score(y_test, prob)\n",
    "\n",
    "d = {\n",
    "  'sensitivity': np.round(sensitivity, 3),\n",
    "  'specificity': np.round(specificity, 3),\n",
    "  'ppv': np.round(ppv, 3),\n",
    "  'npv': np.round(npv, 3),\n",
    "  'f1': np.round(f1, 3),\n",
    "  'auroc': np.round(auroc, 3),\n",
    "  'prevalence': np.round(prevalence, 3),  \n",
    "}\n",
    "\n",
    "metrics = pd.DataFrame(d.values(), index=d.keys(), columns=['Value'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:33:01.720688Z",
     "start_time": "2019-06-28T14:33:00.727780Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "plot_confusion_matrix(ax[0], cm, classes=['not imminent', 'imminent'], normalize=False, title='Confusion matrix')\n",
    "plot_confusion_matrix(ax[1], cm, classes=['not imminent', 'imminent'], normalize=True,\\\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:41:10.571602Z",
     "start_time": "2019-06-28T14:41:10.519646Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = clf.feature_importances_ / clf.feature_importances_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:41:11.930233Z",
     "start_time": "2019-06-28T14:41:10.574459Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "neg_cloud, pos_cloud = get_wordcloud(vectorizer.get_feature_names(), scores, n_words=50)\n",
    "ax[0].imshow(neg_cloud)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Negative Class')\n",
    "ax[1].imshow(pos_cloud)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Positive Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICU Discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:42:45.824136Z",
     "start_time": "2019-06-28T14:42:23.120167Z"
    }
   },
   "outputs": [],
   "source": [
    "df = set_two_splits(discharge_df.copy(), 'test', seed=seed)\n",
    "vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, sublinear_tf=True, ngram_range=(2,2))\n",
    "x_train = vectorizer.fit_transform(df.loc[(df['split'] == 'train')]['scispacy_note'])\n",
    "x_test = vectorizer.transform(df.loc[(df['split'] == 'test')]['scispacy_note'])\n",
    "y_train = df.loc[(df['split'] == 'train')]['discharge_label'].to_numpy()\n",
    "y_test = df.loc[(df['split'] == 'test')]['discharge_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:42:46.164986Z",
     "start_time": "2019-06-28T14:42:45.827657Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape, x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:43:06.568906Z",
     "start_time": "2019-06-28T14:43:06.407965Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 50,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0,\n",
    "    'num_threads': 32,\n",
    "    'min_data_in_leaf': 3,\n",
    "    'num_iterations': 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:53:53.766470Z",
     "start_time": "2019-06-28T14:43:06.577669Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = lightgbm.LGBMClassifier(**parameters)\n",
    "clf.fit(x_train, y_train)\n",
    "prob = clf.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:53:55.935170Z",
     "start_time": "2019-06-28T14:53:54.265629Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plot_thresh_range(ax, y_test, prob, 0.3, 0.7, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:54:49.165722Z",
     "start_time": "2019-06-28T14:54:49.073966Z"
    }
   },
   "outputs": [],
   "source": [
    "args.discharge_threshold = 0.39\n",
    "y_pred = (prob > args.discharge_threshold).astype(np.int64)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn,fp,fn,tp = cm[0][0],cm[0][1],cm[1][0],cm[1][1]\n",
    "prevalence = (fn+tp)/(tn+fp+fn+tp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "ppv = tp/(tp+fp)\n",
    "npv = tn/(tn+fn)\n",
    "f1 = (2*ppv*sensitivity)/(ppv+sensitivity)\n",
    "auroc = roc_auc_score(y_test, prob)\n",
    "\n",
    "d = {\n",
    "  'sensitivity': np.round(sensitivity, 3),\n",
    "  'specificity': np.round(specificity, 3),\n",
    "  'ppv': np.round(ppv, 3),\n",
    "  'npv': np.round(npv, 3),\n",
    "  'f1': np.round(f1, 3),\n",
    "  'auroc': np.round(auroc, 3),\n",
    "  'prevalence': np.round(prevalence, 3),  \n",
    "}\n",
    "\n",
    "metrics = pd.DataFrame(d.values(), index=d.keys(), columns=['Value'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:55:02.488971Z",
     "start_time": "2019-06-28T14:55:01.049151Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "plot_confusion_matrix(ax[0], cm, classes=['not imminent', 'imminent'], normalize=False, title='Confusion matrix')\n",
    "plot_confusion_matrix(ax[1], cm, classes=['not imminent', 'imminent'], normalize=True,\\\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:55:04.606164Z",
     "start_time": "2019-06-28T14:55:04.548563Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = clf.feature_importances_ / clf.feature_importances_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:55:07.498749Z",
     "start_time": "2019-06-28T14:55:06.012751Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "neg_cloud, pos_cloud = get_wordcloud(vectorizer.get_feature_names(), clf.feature_importances_/clf.feature_importances_.sum(), n_words=50)\n",
    "ax[0].imshow(neg_cloud)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Negative Class')\n",
    "ax[1].imshow(pos_cloud)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Positive Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 Seed Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:56:26.641926Z",
     "start_time": "2019-06-28T14:56:26.173625Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 50,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0,\n",
    "    'num_threads': 32,\n",
    "    'min_data_in_leaf': 3,\n",
    "    'num_iterations': 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:57:40.031955Z",
     "start_time": "2019-06-28T14:57:39.623217Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(task, ori_df, threshold):\n",
    "  preds = []\n",
    "  targs = []\n",
    "  probs = []\n",
    "  print(f\"Running for task: {task}\")\n",
    "\n",
    "  for seed in range(args.start_seed, args.start_seed + 100):\n",
    "    if seed % 10 == 0:\n",
    "      print(f\"Running classifier with seed {seed}\")\n",
    "    df = set_two_splits(ori_df.copy(), 'test', seed=seed)\n",
    "    vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, ngram_range=(2,2))\n",
    "\n",
    "    x_train = vectorizer.fit_transform(df.loc[(df['split'] == 'train')]['scispacy_note'])\n",
    "    x_test = vectorizer.transform(df.loc[(df['split'] == 'test')]['scispacy_note'])\n",
    "\n",
    "    y_train = df.loc[(df['split'] == 'train')][f'{task}_label'].to_numpy()\n",
    "    y_test = df.loc[(df['split'] == 'test')][f'{task}_label'].to_numpy()\n",
    "    targs.append(y_test)\n",
    "\n",
    "    clf = lightgbm.LGBMClassifier(**parameters)\n",
    "    clf.fit(x_train, y_train)  \n",
    "    pickle.dump(clf, open(args.modeldir/f'{task}_seed_{seed}.pkl', 'wb'))\n",
    "    \n",
    "    pos_prob = clf.predict_proba(x_test)[:, 1]\n",
    "    probs.append(pos_prob)\n",
    "\n",
    "    y_pred = (pos_prob > threshold).astype(np.int64)\n",
    "    preds.append(y_pred)\n",
    "\n",
    "  with open(args.workdir/f'{task}_preds.pkl', 'wb') as f:\n",
    "    pickle.dump(targs, f)\n",
    "    pickle.dump(preds, f)\n",
    "    pickle.dump(probs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T14:57:50.422084Z",
     "start_time": "2019-06-28T14:57:40.901074Z"
    }
   },
   "outputs": [],
   "source": [
    "run('imminent', imminent_df, args.imminent_threshold)\n",
    "run('discharge', discharge_df, args.discharge_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:49:48.858227Z",
     "start_time": "2019-06-13T19:49:48.744745Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(args.workdir/f'preds.pkl', 'rb') as f:\n",
    "  targs = pickle.load(f)\n",
    "  preds = pickle.load(f)\n",
    "  probs = pickle.load(f)\n",
    "\n",
    "fnames = [f'gbm_seed_{seed}.pkl' for seed in range(args.start_seed, args.start_seed + 100)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:49:55.344475Z",
     "start_time": "2019-06-13T19:49:54.866550Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bam = BinaryAvgMetrics(targs, preds, probs)\n",
    "bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:50:01.185719Z",
     "start_time": "2019-06-13T19:50:00.966426Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bam.get_avg_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:50:07.086096Z",
     "start_time": "2019-06-13T19:50:07.007042Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bam.get_avg_metrics(conf=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:50:13.985605Z",
     "start_time": "2019-06-13T19:50:13.764278Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_best_model(bam, fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:50:25.932771Z",
     "start_time": "2019-06-13T19:50:25.166203Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "plot_mean_roc(ax, bam.targs, bam.probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:50:33.489770Z",
     "start_time": "2019-06-13T19:50:33.200440Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "plot_confusion_matrix(ax[0], bam.cm_avg, classes=['not imminent', 'imminent'], normalize=False,\\\n",
    "                      title='Confusion Matrix Over Runs')\n",
    "plot_confusion_matrix(ax[1], bam.cm_avg, classes=['not imminent', 'imminent'], normalize=True,\\\n",
    "                      title='Normalized Confusion Matrix Over Runs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:55:57.281770Z",
     "start_time": "2019-06-13T19:55:57.136763Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 50,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0,\n",
    "    'num_threads': 32,\n",
    "    'min_data_in_leaf': 3,\n",
    "    'num_iterations': 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:57:46.316883Z",
     "start_time": "2019-06-13T19:55:58.530600Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(args.dataset_csv, usecols=args.cols)\n",
    "vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, sublinear_tf=True,\\\n",
    "                              ngram_range=(2,2))\n",
    "\n",
    "x = vectorizer.fit_transform(df['scispacy_note'])\n",
    "y = df['class_label'].to_numpy()\n",
    "\n",
    "clf = lightgbm.LGBMClassifier(**parameters)\n",
    "clf.fit(x, y)\n",
    "df['prob'] = clf.predict_proba(x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T19:57:52.969280Z",
     "start_time": "2019-06-13T19:57:52.522930Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(args.workdir/'all_data_model.pkl', 'wb') as f:\n",
    "  pickle.dump(clf, f)\n",
    "  pickle.dump(vectorizer.vocabulary_, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
