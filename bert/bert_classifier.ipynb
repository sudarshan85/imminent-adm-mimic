{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Classifier for First ICU Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:26:01.597094Z",
     "start_time": "2019-06-11T16:26:01.570218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:40:11.268084Z",
     "start_time": "2019-06-11T15:40:09.663452Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:40:11.494464Z",
     "start_time": "2019-06-11T15:40:11.270011Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer, BertAdam\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:36:40.113336Z",
     "start_time": "2019-06-11T16:36:39.881083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workdir': PosixPath('../data/work_dir/bert'),\n",
       " 'dataset_csv': PosixPath('../data/processed_dataset.csv'),\n",
       " 'bert_model': 'bert-base-mimic-cased',\n",
       " 'bert_dir': PosixPath('../pretrained/pytorch-bert/bert-base-mimic-cased'),\n",
       " 'max_seq_len': 512,\n",
       " 'do_lower_case': False,\n",
       " 'bs': 128,\n",
       " 'device': 'cuda:3',\n",
       " 'start_seed': 127,\n",
       " 'cols': ['class_label', 'note'],\n",
       " 'labels': [0, 1],\n",
       " 'lr': 5e-05,\n",
       " 'n_epochs': 1,\n",
       " 'wd': 0.1,\n",
       " 'warmup_prop': 0.1,\n",
       " 'schedule': 'warmup_linear'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_classifier.data_processor import read_df, convert_examples_to_features\n",
    "from utils.splits import set_two_splits\n",
    "from args import args\n",
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:40:12.819877Z",
     "start_time": "2019-06-11T15:40:11.574508Z"
    }
   },
   "outputs": [],
   "source": [
    "ori_df = pd.read_csv(args.dataset_csv, usecols=args.cols)\n",
    "df = set_two_splits(ori_df.copy(), 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(args.bert_dir, do_lower_case=args.do_lower_case)\n",
    "train_ex = read_df(df.loc[(df['split'] == 'train')], 'note', 'class_label')\n",
    "train_feats = convert_examples_to_features(train_ex, args.labels, args.max_seq_len, tokenizer)\n",
    "# val_ex = read_df(df.loc[(df['split'] == 'train')], 'note', 'class_label', set_type='val')\n",
    "# val_feats = convert_examples_to_features(val_ex, args.labels, args.max_seq_len, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:57:22.381460Z",
     "start_time": "2019-06-11T15:57:20.049471Z"
    }
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(args.bert_dir, num_labels=1)\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:00:19.105126Z",
     "start_time": "2019-06-11T16:00:17.920653Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([f.input_ids for f in train_feats], dtype=torch.long)\n",
    "input_mask = torch.tensor([f.input_mask for f in train_feats], dtype=torch.long)\n",
    "segment_ids = torch.tensor([f.segment_ids for f in train_feats], dtype=torch.long)\n",
    "label_ids = torch.tensor([f.label_id for f in train_feats], dtype=torch.long)\n",
    "\n",
    "train_ds = TensorDataset(input_ids, input_mask, segment_ids, label_ids)\n",
    "train_dl = DataLoader(train_ds, sampler=RandomSampler(train_ds), batch_size=args.bs)\n",
    "itr = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:07:37.771605Z",
     "start_time": "2019-06-11T16:07:37.521277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 512]),\n",
       " torch.Size([128, 512]),\n",
       " torch.Size([128, 512]),\n",
       " torch.Size([128]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iids, masks, sids, labels = next(itr)\n",
    "iids.shape, masks.shape, sids.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:39:44.415394Z",
     "start_time": "2019-06-11T16:39:44.167227Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:40:51.244864Z",
     "start_time": "2019-06-11T16:40:51.003817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.List[typing.Tuple[int, torch.nn.parameter.Parameter]]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List[Tuple[int, torch.nn.parameter.Parameter]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:40:37.430866Z",
     "start_time": "2019-06-11T16:40:37.411301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(param_optim[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:44:20.754636Z",
     "start_time": "2019-06-11T16:44:20.730151Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_optimizer(named_params: List[Tuple[int, torch.nn.parameter.Parameter]],\n",
    "                    n_steps: int, lr: float, warmup_prop: float, wd: float, schedule='warmup_linear'): \n",
    "  no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "  grouped_params = [\n",
    "    {'params': [p for n, p in param_optim if not any(nd in n for nd in no_decay)], 'weight_decay': wd},\n",
    "    {'params': [p for n, p in param_optim if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "  ]\n",
    "  \n",
    "  return BertAdam(grouped_params, lr=lr, warmup=warmup_prop, t_total=n_steps,\n",
    "                  schedule=schedule, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:38:26.148139Z",
     "start_time": "2019-06-11T16:38:26.126784Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = BertAdam(optim_grouped_params, lr=args.lr, schedule=args.schedule, warmup=args.warmup_prop,\\\n",
    "                     t_total=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:45:13.514841Z",
     "start_time": "2019-06-11T16:45:13.271912Z"
    }
   },
   "outputs": [],
   "source": [
    "n_steps = (len(train_ds)//args.bs) * args.n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:45:22.003660Z",
     "start_time": "2019-06-11T16:45:21.981733Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = build_optimizer(list(model.named_parameters()), n_steps, args.lr,\n",
    "                            args.warmup_prop, args.wd, args.schedule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
