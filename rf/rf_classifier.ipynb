{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First ICU Prediction using Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:31:32.706595Z",
     "start_time": "2019-06-07T19:31:32.695143Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:31:33.970835Z",
     "start_time": "2019-06-07T19:31:32.707813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': PosixPath('../data'),\n",
       " 'workdir': PosixPath('../data/work_dir/rf'),\n",
       " 'dataset_csv': PosixPath('../data/processed_dataset.csv'),\n",
       " 'cols': ['class_label', 'scispacy_note'],\n",
       " 'modeldir': PosixPath('../data/work_dir/rf/models'),\n",
       " 'min_freq': 3,\n",
       " 'bc_threshold': 0.32,\n",
       " 'start_seed': 127}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "from utils.splits import set_two_splits\n",
    "from utils.metrics import BinaryAvgMetrics\n",
    "from utils.plots import *\n",
    "from args import args\n",
    "vars(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF Model Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:31:45.494984Z",
     "start_time": "2019-06-07T19:31:37.860661Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "ori_df = pd.read_csv(args.dataset_csv, usecols=args.cols)\n",
    "df = set_two_splits(ori_df.copy(), 'test', seed=seed)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, sublinear_tf=True,\\\n",
    "                              ngram_range=(2,2))\n",
    "x_train = vectorizer.fit_transform(df.loc[(df['split'] == 'train')]['scispacy_note'])\n",
    "x_test = vectorizer.transform(df.loc[(df['split'] == 'test')]['scispacy_note'])\n",
    "y_train = df.loc[(df['split'] == 'train')]['class_label'].to_numpy()\n",
    "y_test = df.loc[(df['split'] == 'test')]['class_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:33:37.146421Z",
     "start_time": "2019-06-07T19:31:45.497936Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=-1,\\\n",
    "                             min_samples_leaf=3, max_features=0.5, oob_score=True)\n",
    "clf.fit(x_train, y_train)\n",
    "prob = clf.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:17:15.123553Z",
     "start_time": "2019-06-07T19:17:14.974011Z"
    }
   },
   "outputs": [],
   "source": [
    "fi = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:18:30.713955Z",
     "start_time": "2019-06-07T19:18:30.697964Z"
    }
   },
   "outputs": [],
   "source": [
    "fi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:19:01.646756Z",
     "start_time": "2019-06-07T19:19:01.531657Z"
    }
   },
   "outputs": [],
   "source": [
    "fn = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:21:36.767511Z",
     "start_time": "2019-06-07T19:21:36.750291Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:21:49.005039Z",
     "start_time": "2019-06-07T19:21:48.987941Z"
    }
   },
   "outputs": [],
   "source": [
    "for x,y in zip(fi, fn):\n",
    "  print(x, y)\n",
    "  if i == 10:\n",
    "    break\n",
    "  i+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:22:51.957194Z",
     "start_time": "2019-06-07T19:22:51.916742Z"
    }
   },
   "outputs": [],
   "source": [
    "x = sorted(zip(np.round(fi, 3), fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:24:21.095013Z",
     "start_time": "2019-06-07T19:24:21.074838Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.argsort(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:34:43.792964Z",
     "start_time": "2019-06-07T19:34:43.598146Z"
    }
   },
   "outputs": [],
   "source": [
    "def top_words(feature_names, probs, N):\n",
    "  words = sorted(zip(probs, feature_names), reverse=True)\n",
    "  pos = words[:N]\n",
    "  neg = words[:-(N + 1):-1]\n",
    "\n",
    "  print(\"Words associated with imminent threat: \")\n",
    "  for feat in pos:\n",
    "    print(np.round(feat[0], 2), feat[1])\n",
    "\n",
    "  print(\"***********************************************\")\n",
    "  print(\"Words associated with not imminent threat: \")   \n",
    "  for feat in neg:\n",
    "    print(np.round(feat[0], 2), feat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:34:44.373247Z",
     "start_time": "2019-06-07T19:34:44.144005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words associated with imminent threat: \n",
      "0.07 _\n",
      "0.05 REPORT\n",
      "0.03 Radiology\n",
      "0.03 Transfer\n",
      "0.02 Clip\n",
      "0.01 intubated\n",
      "0.01 floor\n",
      "0.01 tube\n",
      "0.01 vent\n",
      "0.01 transfer\n",
      "0.01 PA\n",
      "0.0 ,\n",
      "0.0 home\n",
      "0.0 LAT\n",
      "0.0 Number\n",
      "0.0 REASON\n",
      "0.0 with\n",
      "0.0 Reason\n",
      "0.0 and\n",
      "0.0 of\n",
      "***********************************************\n",
      "Words associated with not imminent threat: \n",
      "0.0 \u0013\n",
      "0.0 $\n",
      "0.0 'll\n",
      "0.0 're\n",
      "0.0 've\n",
      "0.0 (+)-\n",
      "0.0 (+)BOWEL\n",
      "0.0 (+)BS\n",
      "0.0 (+)BSx4\n",
      "0.0 (+)CHF--\n",
      "0.0 (+)GIB\n",
      "0.0 (+)bowel\n",
      "0.0 (+)bs\n",
      "0.0 (+)palpable\n",
      "0.0 (-).He\n",
      "0.0 (-)1L\n",
      "0.0 (-)500\n",
      "0.0 (-)500cc\n",
      "0.0 (-)BM\n",
      "0.0 (-)DVT\n"
     ]
    }
   ],
   "source": [
    "top_words(vectorizer.get_feature_names(), clf.feature_importances_, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:26:31.487426Z",
     "start_time": "2019-06-07T19:26:31.419172Z"
    }
   },
   "outputs": [],
   "source": [
    "top_words = sorted(zip(fi, fn), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:27:29.285061Z",
     "start_time": "2019-06-07T19:27:29.265289Z"
    }
   },
   "outputs": [],
   "source": [
    "top_words[:-(20 + 1):-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:20:25.841826Z",
     "start_time": "2019-06-07T19:20:25.824299Z"
    }
   },
   "outputs": [],
   "source": [
    "N=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:28:58.803108Z",
     "start_time": "2019-06-07T19:28:58.607639Z"
    }
   },
   "outputs": [],
   "source": [
    "pos = coefs_with_fns[:N]\n",
    "neg = coefs_with_fns[:-(N + 1):-1]\n",
    "\n",
    "print(\"Words associated with imminent threat: \")\n",
    "for feat in pos:\n",
    "    print(feat)\n",
    "\n",
    "print(\"Words associated with not imminent threat: \")\n",
    "for feat in neg:\n",
    "    print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:14:05.024924Z",
     "start_time": "2019-06-07T19:14:04.322529Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plot_thresh_range(ax, y_test, prob, 0.3, 0.7, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:14:53.803600Z",
     "start_time": "2019-06-07T19:14:53.765723Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = (prob > 0.32).astype(np.int64)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn,fp,fn,tp = cm[0][0],cm[0][1],cm[1][0],cm[1][1]\n",
    "prevalence = (fn+tp)/(tn+fp+fn+tp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "ppv = tp/(tp+fp)\n",
    "npv = tn/(tn+fn)\n",
    "f1 = (2*ppv*sensitivity)/(ppv+sensitivity)\n",
    "auroc = roc_auc_score(y_test, prob)\n",
    "\n",
    "d = {\n",
    "  'sensitivity': np.round(sensitivity, 3),\n",
    "  'specificity': np.round(specificity, 3),\n",
    "  'ppv': np.round(ppv, 3),\n",
    "  'npv': np.round(npv, 3),\n",
    "  'f1': np.round(f1, 3),\n",
    "  'auroc': np.round(auroc, 3),\n",
    "  'prevalence': np.round(prevalence, 3),  \n",
    "}\n",
    "\n",
    "metrics = pd.DataFrame(d.values(), index=d.keys(), columns=['Value'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:15:32.331965Z",
     "start_time": "2019-05-23T01:14:53.688763Z"
    }
   },
   "outputs": [],
   "source": [
    "ori_df = pd.read_csv(args.dataset_csv, usecols=args.cols)\n",
    "preds = []\n",
    "targs = []\n",
    "probs = []\n",
    "\n",
    "for seed in range(args.start_seed, args.start_seed + 100):\n",
    "  if seed % 10 == 0:\n",
    "    print(f\"Running classifier with seed {seed}\")\n",
    "  df = set_two_splits(ori_df.copy(), 'test', seed=seed)\n",
    "  vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, ngram_range=(2,2))\n",
    "  \n",
    "  x_train = vectorizer.fit_transform(df.loc[(df['split'] == 'train')]['scispacy_note'])\n",
    "  x_test = vectorizer.transform(df.loc[(df['split'] == 'test')]['scispacy_note'])\n",
    "  \n",
    "  y_train = df.loc[(df['split'] == 'train')]['class_label'].to_numpy()\n",
    "  y_test = df.loc[(df['split'] == 'test')]['class_label'].to_numpy()\n",
    "  targs.append(y_test)\n",
    "  \n",
    "  clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=-1,\\\n",
    "                             min_samples_leaf=3, max_features=0.5, oob_score=True)\n",
    "  clf.fit(x_train, y_train)  \n",
    "  pickle.dump(clf, open(args.modeldir/f'lr_seed_{seed}.pkl', 'wb'))\n",
    "  \n",
    "  prob = clf.predict_proba(x_test)[:, 1]\n",
    "  probs.append(prob)\n",
    "  \n",
    "  y_pred = (prob > args.bc_threshold).astype(np.int64)\n",
    "  preds.append(y_pred)\n",
    "\n",
    "with open(args.workdir/f'preds.pkl', 'wb') as f:\n",
    "  pickle.dump(targs, f)\n",
    "  pickle.dump(preds, f)\n",
    "  pickle.dump(probs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from [here](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/):\n",
    "\n",
    "1. Prevalence: `(fn + tp) / total`\n",
    "2. Sensitivity: AKA recall, true positive rate `tp / (tp + fn)`\n",
    "3. Specificity: AKA true negative rate `tn / (tn + fp)`\n",
    "4. Positive Predictive Value (PPV): AKA precision `tp / (tp + fp)`\n",
    "5. Negative Predictive Value (NPV): `tn / (tn + fn)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T11:23:23.929433Z",
     "start_time": "2019-05-23T11:23:23.888470Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(args.workdir/f'preds.pkl', 'rb') as f:\n",
    "  targs = pickle.load(f)\n",
    "  preds = pickle.load(f)\n",
    "  probs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T11:31:32.893430Z",
     "start_time": "2019-05-23T11:31:32.311619Z"
    }
   },
   "outputs": [],
   "source": [
    "bam = BinaryAvgMetrics(targs, preds, probs)\n",
    "bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T11:31:39.956062Z",
     "start_time": "2019-05-23T11:31:39.754889Z"
    }
   },
   "outputs": [],
   "source": [
    "bam.get_avg_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T11:32:08.817951Z",
     "start_time": "2019-05-23T11:32:08.787936Z"
    }
   },
   "outputs": [],
   "source": [
    "bam.get_avg_metrics(conf=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T11:18:11.721793Z",
     "start_time": "2019-05-23T11:18:11.084118Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "plot_mean_roc(ax, bam.targs, bam.probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T11:18:11.953544Z",
     "start_time": "2019-05-23T11:18:11.723238Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "plot_confusion_matrix(ax[0], bam.cm_avg, classes=['not imminent', 'imminent'], normalize=False,\\\n",
    "                      title='Confusion Matrix Over Runs')\n",
    "plot_confusion_matrix(ax[1], bam.cm_avg, classes=['not imminent', 'imminent'], normalize=True,\\\n",
    "                      title='Normalized Confusion Matrix Over Runs')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
