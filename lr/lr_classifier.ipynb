{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First ICU Prediction using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:43:54.036949Z",
     "start_time": "2019-06-07T19:43:54.024487Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:43:55.385001Z",
     "start_time": "2019-06-07T19:43:54.038243Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': PosixPath('../data'),\n",
       " 'workdir': PosixPath('../data/work_dir/lr'),\n",
       " 'dataset_csv': PosixPath('../data/processed_dataset.csv'),\n",
       " 'cols': ['class_label', 'scispacy_note'],\n",
       " 'modeldir': PosixPath('../data/work_dir/lr/models'),\n",
       " 'min_freq': 3,\n",
       " 'bc_threshold': 0.47,\n",
       " 'start_seed': 127}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import interp, stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "from utils.splits import set_two_splits\n",
    "from utils.metrics import BinaryAvgMetrics, get_best_model\n",
    "from utils.plots import *\n",
    "from args import args\n",
    "vars(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:43:55.404969Z",
     "start_time": "2019-06-07T19:43:55.386633Z"
    }
   },
   "outputs": [],
   "source": [
    "def top_words(feature_names, probs, N):\n",
    "  words = sorted(zip(probs, feature_names), reverse=True)\n",
    "  pos = words[:N]\n",
    "  neg = words[:-(N + 1):-1]\n",
    "\n",
    "  print(\"Words associated with imminent threat: \")\n",
    "  for feat in pos:\n",
    "    print(np.round(feat[0], 2), feat[1])\n",
    "\n",
    "  print(\"***********************************************\")\n",
    "  print(\"Words associated with not imminent threat: \")   \n",
    "  for feat in neg:\n",
    "    print(np.round(feat[0], 2), feat[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Model Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:44:03.096558Z",
     "start_time": "2019-06-07T19:43:55.406304Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "ori_df = pd.read_csv(args.dataset_csv, usecols=args.cols)\n",
    "df = set_two_splits(ori_df.copy(), 'test', seed=seed)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, sublinear_tf=True,\\\n",
    "                              ngram_range=(2,2))\n",
    "x_train = vectorizer.fit_transform(df.loc[(df['split'] == 'train')]['scispacy_note'])\n",
    "x_test = vectorizer.transform(df.loc[(df['split'] == 'test')]['scispacy_note'])\n",
    "y_train = df.loc[(df['split'] == 'train')]['class_label'].to_numpy()\n",
    "y_test = df.loc[(df['split'] == 'test')]['class_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:44:04.145862Z",
     "start_time": "2019-06-07T19:44:03.104281Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(dual=True, class_weight='balanced', solver='liblinear', C=1.5)\n",
    "clf.fit(x_train, y_train)\n",
    "prob = clf.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T13:14:17.385469Z",
     "start_time": "2019-06-07T13:14:16.871647Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plot_thresh_range(ax, y_test, prob, 0.3, 0.7, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T13:14:32.246668Z",
     "start_time": "2019-06-07T13:14:32.112804Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = (prob > 0.47).astype(np.int64)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn,fp,fn,tp = cm[0][0],cm[0][1],cm[1][0],cm[1][1]\n",
    "prevalence = (fn+tp)/(tn+fp+fn+tp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "ppv = tp/(tp+fp)\n",
    "npv = tn/(tn+fn)\n",
    "f1 = (2*ppv*sensitivity)/(ppv+sensitivity)\n",
    "auroc = roc_auc_score(y_test, prob)\n",
    "\n",
    "d = {\n",
    "  'sensitivity': np.round(sensitivity, 3),\n",
    "  'specificity': np.round(specificity, 3),\n",
    "  'ppv': np.round(ppv, 3),\n",
    "  'npv': np.round(npv, 3),\n",
    "  'f1': np.round(f1, 3),\n",
    "  'auroc': np.round(auroc, 3),\n",
    "  'prevalence': np.round(prevalence, 3),  \n",
    "}\n",
    "\n",
    "metrics = pd.DataFrame(d.values(), index=d.keys(), columns=['Value'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T13:14:36.508824Z",
     "start_time": "2019-06-07T13:14:36.272179Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "plot_confusion_matrix(ax[0], cm, classes=['not imminent', 'imminent'], normalize=False, title='Confusion matrix')\n",
    "plot_confusion_matrix(ax[1], cm, classes=['not imminent', 'imminent'], normalize=True,\\\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T19:44:04.268516Z",
     "start_time": "2019-06-07T19:44:04.147951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words associated with imminent threat: \n",
      "0.02 intubated\n",
      "0.02 vent\n",
      "0.02 OSH\n",
      "0.01 support\n",
      "0.01 Progress\n",
      "0.01 gtt\n",
      "0.01 MULTIPLE\n",
      "0.01 ETT\n",
      "0.01 Endotracheal\n",
      "0.01 P\n",
      "0.01 shock\n",
      "0.01 sepsis\n",
      "0.01 endocarditis\n",
      "0.01 ABG\n",
      "0.01 ET\n",
      "0.01 endotracheal\n",
      "0.01 HYPOTENSION\n",
      "0.01 PORT\n",
      "0.01 PEDESTRIAN\n",
      "0.01 IABP\n",
      "***********************************************\n",
      "Words associated with not imminent threat: \n",
      "-0.02 Transfer\n",
      "-0.02 transfer\n",
      "-0.02 floor\n",
      "-0.01 Age\n",
      "-0.01 FRACTURE\n",
      "-0.01 2137\n",
      "-0.01 lobectomy\n",
      "-0.01 _\n",
      "-0.01 TRANSFER\n",
      "-0.01 dementia\n",
      "-0.01 home\n",
      "-0.01 2118\n",
      "-0.01 PACU\n",
      "-0.01 hep\n",
      "-0.01 diet\n",
      "-0.01 VALVE\n",
      "-0.01 O2\n",
      "-0.01 melanoma\n",
      "-0.01 LOBE\n",
      "-0.01 FLOOR\n"
     ]
    }
   ],
   "source": [
    "top_words(vectorizer.get_feature_names(), clf.coef_[0]/np.sum(clf.coef_[0]), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T17:16:45.923944Z",
     "start_time": "2019-06-07T17:04:40.891332Z"
    }
   },
   "outputs": [],
   "source": [
    "ori_df = pd.read_csv(args.dataset_csv, usecols=args.cols)\n",
    "preds = []\n",
    "targs = []\n",
    "probs = []\n",
    "\n",
    "for seed in range(args.start_seed, args.start_seed + 100):\n",
    "  if seed % 10 == 0:\n",
    "    print(f\"Running classifier with seed {seed}\")\n",
    "  df = set_two_splits(ori_df.copy(), 'test', seed=seed)\n",
    "  vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, ngram_range=(2,2))\n",
    "  \n",
    "  x_train = vectorizer.fit_transform(df.loc[(df['split'] == 'train')]['scispacy_note'])\n",
    "  x_test = vectorizer.transform(df.loc[(df['split'] == 'test')]['scispacy_note'])\n",
    "  \n",
    "  y_train = df.loc[(df['split'] == 'train')]['class_label'].to_numpy()\n",
    "  y_test = df.loc[(df['split'] == 'test')]['class_label'].to_numpy()\n",
    "  targs.append(y_test)\n",
    "  \n",
    "  clf = LogisticRegression(dual=True, class_weight='balanced', solver='liblinear', C=1.5)\n",
    "  clf.fit(x_train, y_train)  \n",
    "  pickle.dump(clf, open(args.modeldir/f'lr_seed_{seed}.pkl', 'wb'))\n",
    "  \n",
    "  pos_prob = clf.predict_proba(x_test)[:, 1]\n",
    "  probs.append(pos_prob)\n",
    "  \n",
    "  y_pred = (pos_prob > args.bc_threshold).astype(np.int64)\n",
    "  preds.append(y_pred)\n",
    "\n",
    "with open(args.workdir/f'preds.pkl', 'wb') as f:\n",
    "  pickle.dump(targs, f)\n",
    "  pickle.dump(preds, f)\n",
    "  pickle.dump(probs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Determine Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T13:34:18.639631Z",
     "start_time": "2019-06-07T13:34:10.987732Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "ori_df = pd.read_csv(args.dataset_csv, usecols=args.cols)\n",
    "df = set_two_splits(ori_df.copy(), 'test', seed=seed)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=args.min_freq, analyzer=str.split, sublinear_tf=True,\\\n",
    "                              ngram_range=(2,2))\n",
    "x_train = vectorizer.fit_transform(df.loc[(df['split'] == 'train')]['scispacy_note'])\n",
    "x_test = vectorizer.transform(df.loc[(df['split'] == 'test')]['scispacy_note'])\n",
    "y_train = df.loc[(df['split'] == 'train')]['class_label'].to_numpy()\n",
    "y_test = df.loc[(df['split'] == 'test')]['class_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T13:34:18.690671Z",
     "start_time": "2019-06-07T13:34:18.669398Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf = pickle.load(open(args.modeldir/fnames[0], 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T13:34:27.960658Z",
     "start_time": "2019-06-07T13:34:27.939853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pos_prob = clf.predict_proba(x_test)[:, 1]\n",
    "y_pred = (pos_prob > args.bc_threshold).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T13:35:17.205291Z",
     "start_time": "2019-06-07T13:35:16.876435Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = (prob > args.bc_threshold).astype(np.int64)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn,fp,fn,tp = cm[0][0],cm[0][1],cm[1][0],cm[1][1]\n",
    "prevalence = (fn+tp)/(tn+fp+fn+tp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "ppv = tp/(tp+fp)\n",
    "npv = tn/(tn+fn)\n",
    "f1 = (2*ppv*sensitivity)/(ppv+sensitivity)\n",
    "auroc = roc_auc_score(y_test, prob)\n",
    "\n",
    "d = {\n",
    "  'sensitivity': np.round(sensitivity, 3),\n",
    "  'specificity': np.round(specificity, 3),\n",
    "  'ppv': np.round(ppv, 3),\n",
    "  'npv': np.round(npv, 3),\n",
    "  'f1': np.round(f1, 3),\n",
    "  'auroc': np.round(auroc, 3),\n",
    "  'prevalence': np.round(prevalence, 3),  \n",
    "}\n",
    "\n",
    "metrics = pd.DataFrame(d.values(), index=d.keys(), columns=['Value'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from [here](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/):\n",
    "\n",
    "1. Prevalence: `(fn + tp) / total`\n",
    "2. Sensitivity: AKA recall, true positive rate `tp / (tp + fn)`\n",
    "3. Specificity: AKA true negative rate `tn / (tn + fp)`\n",
    "4. Positive Predictive Value (PPV): AKA precision `tp / (tp + fp)`\n",
    "5. Negative Predictive Value (NPV): `tn / (tn + fn)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T17:17:25.858811Z",
     "start_time": "2019-06-07T17:17:25.678086Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(args.workdir/f'preds.pkl', 'rb') as f:\n",
    "  targs = pickle.load(f)\n",
    "  preds = pickle.load(f)\n",
    "  probs = pickle.load(f)\n",
    "\n",
    "fnames = [f'lr_seed_{seed}.pkl' for seed in range(args.start_seed, args.start_seed + 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T17:17:27.417523Z",
     "start_time": "2019-06-07T17:17:26.972245Z"
    }
   },
   "outputs": [],
   "source": [
    "bam = BinaryAvgMetrics(targs, preds, probs)\n",
    "bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T17:17:29.730465Z",
     "start_time": "2019-06-07T17:17:29.524781Z"
    }
   },
   "outputs": [],
   "source": [
    "get_best_model(bam, fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T17:18:00.877674Z",
     "start_time": "2019-06-07T17:18:00.670801Z"
    }
   },
   "outputs": [],
   "source": [
    "bam.get_avg_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T17:18:00.901716Z",
     "start_time": "2019-06-07T17:18:00.879088Z"
    }
   },
   "outputs": [],
   "source": [
    "bam.get_avg_metrics(conf=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T17:18:17.575062Z",
     "start_time": "2019-06-07T17:18:16.902897Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "plot_mean_roc(ax, bam.targs, bam.probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T17:18:19.595484Z",
     "start_time": "2019-06-07T17:18:19.262293Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "plot_confusion_matrix(ax[0], bam.cm_avg, classes=['not imminent', 'imminent'], normalize=False,\\\n",
    "                      title='Confusion Matrix Over Runs')\n",
    "plot_confusion_matrix(ax[1], bam.cm_avg, classes=['not imminent', 'imminent'], normalize=True,\\\n",
    "                      title='Normalized Confusion Matrix Over Runs')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
