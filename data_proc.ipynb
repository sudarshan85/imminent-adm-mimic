{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation for First ICU Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:24:34.089174Z",
     "start_time": "2019-06-12T14:24:34.075752Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:24:35.436851Z",
     "start_time": "2019-06-12T14:24:34.090464Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:24:35.456219Z",
     "start_time": "2019-06-12T14:24:35.438391Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:24:35.474516Z",
     "start_time": "2019-06-12T14:24:35.457550Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sample(df, sample_pct=0.01, with_val=True, seed=None):\n",
    "  train = df.loc[(df['split']) == 'train'].sample(frac=sample_pct, random_state=seed)\n",
    "  train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "  if with_val:\n",
    "    val = df.loc[(df['split']) == 'val'].sample(frac=sample_pct, random_state=seed)\n",
    "    val.reset_index(inplace=True, drop=True)\n",
    "    return pd.concat([train, val], axis=0) \n",
    "\n",
    "  return train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load in the data\n",
    "2. Drop duplicates\n",
    "3. Merge `category`, `description`, and `text` into a new column called `note`\n",
    "4. Tokenize text using `scispacy` and create new column called `scispacy_note` to save tokenized text\n",
    "5. Save the relevant columns to a csv file onto disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T11:03:44.341016Z",
     "start_time": "2019-06-10T11:03:44.324417Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "  tokens = [token.text for token in nlp(text)]\n",
    "  return ' '.join(tokens)\n",
    "\n",
    "def group_eth(eth):\n",
    "  eth = eth.lower()\n",
    "  if 'white' in eth:\n",
    "    return 'white'\n",
    "  elif 'black' in eth:\n",
    "    return 'black'\n",
    "  elif 'hispanic' in eth:\n",
    "    return 'hispanic'\n",
    "  elif 'asian' in eth:\n",
    "    return 'asian'\n",
    "  else:\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T11:03:45.818747Z",
     "start_time": "2019-06-10T11:03:44.342107Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_sci_md', disable=['parser', 'ner', 'tagger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T12:52:34.698639Z",
     "start_time": "2019-06-07T12:50:33.008312Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'raw_dataset.csv')\n",
    "df.drop_duplicates(inplace=True)\n",
    "df['note'] = df['category'].str.cat(df['description'], sep='\\n')\n",
    "df['note'] = df['note'].str.cat(df['text'], sep='\\n')\n",
    "df['ethnicity'] = df['ethnicity'].apply(group_eth)\n",
    "df['scispacy_note'] = df['note'].apply(tokenize_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T12:52:39.205820Z",
     "start_time": "2019-06-07T12:52:34.700150Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(path/'processed_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T11:04:09.919642Z",
     "start_time": "2019-06-10T11:04:08.732716Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(path/'full_raw_dataset.csv')\n",
    "\n",
    "full_df.drop_duplicates(inplace=True)\n",
    "full_df['note'] = full_df['category'].str.cat(full_df['description'], sep='\\n')\n",
    "full_df['note'] = full_df['note'].str.cat(full_df['text'], sep='\\n')\n",
    "full_df['ethnicity'] = full_df['ethnicity'].apply(group_eth)\n",
    "full_df['scispacy_note'] = full_df['note'].apply(tokenize_text)\n",
    "print(full_df.shape)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T09:50:08.666362Z",
     "start_time": "2019-06-10T09:50:02.208402Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df.to_csv(path/'full_processed_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:24:56.580981Z",
     "start_time": "2019-06-12T14:24:56.137824Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.splits import set_two_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:25:38.172542Z",
     "start_time": "2019-06-12T14:25:35.610165Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'processed_dataset.csv')\n",
    "df_split = set_two_splits(df[['note', 'class_label']].copy(), 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:25:45.773160Z",
     "start_time": "2019-06-12T14:25:45.740324Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sample = get_sample(df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:26:11.669665Z",
     "start_time": "2019-06-12T14:26:11.565364Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sample.loc[(df_split['split'] == 'train')].to_csv(path/'bert_processed_train.tsv', sep='\\t',\n",
    "                                                    index_label='index')\n",
    "df_sample.loc[(df_split['split'] == 'val')].to_csv(path/'bert_processed_val.tsv', sep='\\t',\n",
    "                                                  index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:26:12.554283Z",
     "start_time": "2019-06-12T14:26:12.507957Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'bert_processed_train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T19:52:51.586654Z",
     "start_time": "2019-06-06T19:52:49.199286Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'processed_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T20:54:57.718667Z",
     "start_time": "2019-06-06T20:54:57.677318Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[(df['class_label'] == 0)].groupby('category').apply(lambda g: pd.Series(g['subject_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T20:58:49.439931Z",
     "start_time": "2019-06-06T20:58:49.273675Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[(df['class_label'] == 0)].groupby('category').size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
