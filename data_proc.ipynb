{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation for First ICU Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:32:19.915284Z",
     "start_time": "2019-06-17T19:32:19.901838Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:32:21.223758Z",
     "start_time": "2019-06-17T19:32:19.916778Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:32:21.245322Z",
     "start_time": "2019-06-17T19:32:21.225728Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:32:21.264610Z",
     "start_time": "2019-06-17T19:32:21.246616Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sample(df, sample_pct=0.01, with_val=True, seed=None):\n",
    "  train = df.loc[(df['split']) == 'train'].sample(frac=sample_pct, random_state=seed)\n",
    "  train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "  if with_val:\n",
    "    val = df.loc[(df['split']) == 'val'].sample(frac=sample_pct, random_state=seed)\n",
    "    val.reset_index(inplace=True, drop=True)\n",
    "    return pd.concat([train, val], axis=0) \n",
    "\n",
    "  return train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load in the data\n",
    "2. Drop duplicates\n",
    "3. Merge `category`, `description`, and `text` into a new column called `note`\n",
    "4. Tokenize text using `scispacy` and create new column called `scispacy_note` to save tokenized text\n",
    "5. Save the relevant columns to a csv file onto disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T11:03:44.341016Z",
     "start_time": "2019-06-10T11:03:44.324417Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "  tokens = [token.text for token in nlp(text)]\n",
    "  return ' '.join(tokens)\n",
    "\n",
    "def group_eth(eth):\n",
    "  eth = eth.lower()\n",
    "  if 'white' in eth:\n",
    "    return 'white'\n",
    "  elif 'black' in eth:\n",
    "    return 'black'\n",
    "  elif 'hispanic' in eth:\n",
    "    return 'hispanic'\n",
    "  elif 'asian' in eth:\n",
    "    return 'asian'\n",
    "  else:\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T11:03:45.818747Z",
     "start_time": "2019-06-10T11:03:44.342107Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_sci_md', disable=['parser', 'ner', 'tagger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T12:52:34.698639Z",
     "start_time": "2019-06-07T12:50:33.008312Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'raw_dataset.csv')\n",
    "df.drop_duplicates(inplace=True)\n",
    "df['note'] = df['category'].str.cat(df['description'], sep='\\n')\n",
    "df['note'] = df['note'].str.cat(df['text'], sep='\\n')\n",
    "df['ethnicity'] = df['ethnicity'].apply(group_eth)\n",
    "df['scispacy_note'] = df['note'].apply(tokenize_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T12:52:39.205820Z",
     "start_time": "2019-06-07T12:52:34.700150Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(path/'processed_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T11:04:09.919642Z",
     "start_time": "2019-06-10T11:04:08.732716Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(path/'full_raw_dataset.csv')\n",
    "\n",
    "full_df.drop_duplicates(inplace=True)\n",
    "full_df['note'] = full_df['category'].str.cat(full_df['description'], sep='\\n')\n",
    "full_df['note'] = full_df['note'].str.cat(full_df['text'], sep='\\n')\n",
    "full_df['ethnicity'] = full_df['ethnicity'].apply(group_eth)\n",
    "full_df['scispacy_note'] = full_df['note'].apply(tokenize_text)\n",
    "print(full_df.shape)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T09:50:08.666362Z",
     "start_time": "2019-06-10T09:50:02.208402Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df.to_csv(path/'full_processed_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:24:56.580981Z",
     "start_time": "2019-06-12T14:24:56.137824Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.splits import set_two_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:25:38.172542Z",
     "start_time": "2019-06-12T14:25:35.610165Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'processed_dataset.csv')\n",
    "df_split = set_two_splits(df[['note', 'class_label']].copy(), 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:25:45.773160Z",
     "start_time": "2019-06-12T14:25:45.740324Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sample = get_sample(df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:26:11.669665Z",
     "start_time": "2019-06-12T14:26:11.565364Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sample.loc[(df_split['split'] == 'train')].to_csv(path/'bert_processed_train.tsv', sep='\\t',\n",
    "                                                    index_label='index')\n",
    "df_sample.loc[(df_split['split'] == 'val')].to_csv(path/'bert_processed_val.tsv', sep='\\t',\n",
    "                                                  index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:26:12.554283Z",
     "start_time": "2019-06-12T14:26:12.507957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'bert_processed_train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:32:25.339813Z",
     "start_time": "2019-06-17T19:32:22.791615Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'processed_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:39:23.394117Z",
     "start_time": "2019-06-17T19:39:23.184004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.236\n"
     ]
    }
   ],
   "source": [
    "print(f\"{(len(df.loc[df['class_label'] == 1])/len(df)):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:33:46.321426Z",
     "start_time": "2019-06-17T19:33:46.269517Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.splits import set_two_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:43:37.732639Z",
     "start_time": "2019-06-17T19:43:29.578242Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_p = []\n",
    "\n",
    "for seed in range(127, 227):\n",
    "  sdf = set_two_splits(df.copy(), name='test', seed=seed)\n",
    "  test_size = len(sdf.loc[(sdf['split'] == 'test')])\n",
    "  test_pos = len(sdf.loc[(sdf['split'] == 'test') & (sdf['class_label'] == 1)])\n",
    "  avg_p.append(test_pos/test_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:43:41.371503Z",
     "start_time": "2019-06-17T19:43:41.349497Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_p = np.array(avg_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:43:50.438308Z",
     "start_time": "2019-06-17T19:43:50.417839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average prevalence = 0.236\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average prevalence = {(avg_p.mean()):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:44:07.665061Z",
     "start_time": "2019-06-17T19:44:07.642882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std prevalance = 0.004\n"
     ]
    }
   ],
   "source": [
    "print(f\"Std prevalance = {(avg_p.std()):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T20:54:57.718667Z",
     "start_time": "2019-06-06T20:54:57.677318Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[(df['class_label'] == 0)].groupby('category').apply(lambda g: pd.Series(g['subject_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T20:58:49.439931Z",
     "start_time": "2019-06-06T20:58:49.273675Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[(df['class_label'] == 0)].groupby('category').size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
