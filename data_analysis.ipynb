{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation for First ICU Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:03:58.298087Z",
     "start_time": "2019-06-26T14:03:58.229207Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:08:58.435535Z",
     "start_time": "2019-06-26T14:08:57.823830Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style = 'darkgrid')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:03:59.131558Z",
     "start_time": "2019-06-26T14:03:59.113508Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('./data')\n",
    "raw_csv = path/'mimic_icu_pred_raw_dataset.csv'\n",
    "proc_csv = path/'mimic_icu_pred_proc_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:04:01.419612Z",
     "start_time": "2019-06-26T14:04:01.397875Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sample(df, sample_pct=0.01, with_val=True, seed=None):\n",
    "  train = df.loc[(df['split']) == 'train'].sample(frac=sample_pct, random_state=seed)\n",
    "  train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "  if with_val:\n",
    "    val = df.loc[(df['split']) == 'val'].sample(frac=sample_pct, random_state=seed)\n",
    "    val.reset_index(inplace=True, drop=True)\n",
    "    return pd.concat([train, val], axis=0) \n",
    "\n",
    "  return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:04:01.439403Z",
     "start_time": "2019-06-26T14:04:01.421113Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "  tokens = [token.text for token in nlp(text)]\n",
    "  return ' '.join(tokens)\n",
    "\n",
    "def group_eth(eth):\n",
    "  eth = eth.lower()\n",
    "  if 'white' in eth:\n",
    "    return 'white'\n",
    "  elif 'black' in eth:\n",
    "    return 'black'\n",
    "  elif 'hispanic' in eth:\n",
    "    return 'hispanic'\n",
    "  elif 'asian' in eth:\n",
    "    return 'asian'\n",
    "  else:\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load in the data\n",
    "2. Drop duplicates\n",
    "3. Merge `category`, `description`, and `text` into a new column called `note`\n",
    "4. Tokenize text using `scispacy` and create new column called `scispacy_note` to save tokenized text\n",
    "5. Save a csv file onto disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:04:02.925949Z",
     "start_time": "2019-06-26T14:04:01.440602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76370, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(raw_csv)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:07:11.448469Z",
     "start_time": "2019-06-26T14:04:08.423365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75271, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_sci_md', disable=['parser', 'ner', 'tagger'])\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df['note'] = df['category'].str.cat(df['description'], sep='\\n')\n",
    "df['note'] = df['note'].str.cat(df['text'], sep='\\n')\n",
    "df['ethnicity'] = df['ethnicity'].apply(group_eth)\n",
    "df['scispacy_note'] = df['note'].apply(tokenize_text)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:07:22.782915Z",
     "start_time": "2019-06-26T14:07:15.900139Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(proc_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:10:12.590410Z",
     "start_time": "2019-06-26T14:10:12.357471Z"
    }
   },
   "outputs": [],
   "source": [
    "hfont = {'fontname':'Helvetica'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "sns.distplot(df, kde=False, ax=ax, bins=80)\n",
    "ax.set_xlabel('ICU LOS (days)', fontweight='bold', fontsize=15)\n",
    "ax.set_ylabel('Number of notes', fontweight='bold', fontsize=15)\n",
    "ax.set_xlim(0, 40)\n",
    "ax.text(ax.get_xlim()[1]*0.50, ax.get_ylim()[1]*0.80, f\"Min: {df['icu_los'].min()}, Avg: {df['icu_los'].mean(): 0.2f}, Max: {df['icu_los'].max()}\", fontweight='bold', fontsize=15, ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T12:52:34.698639Z",
     "start_time": "2019-06-07T12:50:33.008312Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'raw_dataset.csv')\n",
    "df.drop_duplicates(inplace=True)\n",
    "df['note'] = df['category'].str.cat(df['description'], sep='\\n')\n",
    "df['note'] = df['note'].str.cat(df['text'], sep='\\n')\n",
    "df['ethnicity'] = df['ethnicity'].apply(group_eth)\n",
    "df['scispacy_note'] = df['note'].apply(tokenize_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T12:52:39.205820Z",
     "start_time": "2019-06-07T12:52:34.700150Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(path/'processed_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T11:04:09.919642Z",
     "start_time": "2019-06-10T11:04:08.732716Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(path/'full_raw_dataset.csv')\n",
    "\n",
    "full_df.drop_duplicates(inplace=True)\n",
    "full_df['note'] = full_df['category'].str.cat(full_df['description'], sep='\\n')\n",
    "full_df['note'] = full_df['note'].str.cat(full_df['text'], sep='\\n')\n",
    "full_df['ethnicity'] = full_df['ethnicity'].apply(group_eth)\n",
    "full_df['scispacy_note'] = full_df['note'].apply(tokenize_text)\n",
    "print(full_df.shape)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T09:50:08.666362Z",
     "start_time": "2019-06-10T09:50:02.208402Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df.to_csv(path/'full_processed_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:32:25.339813Z",
     "start_time": "2019-06-17T19:32:22.791615Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'processed_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:39:23.394117Z",
     "start_time": "2019-06-17T19:39:23.184004Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"{(len(df.loc[df['class_label'] == 1])/len(df)):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:33:46.321426Z",
     "start_time": "2019-06-17T19:33:46.269517Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.splits import set_two_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:43:37.732639Z",
     "start_time": "2019-06-17T19:43:29.578242Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_p = []\n",
    "\n",
    "for seed in range(127, 227):\n",
    "  sdf = set_two_splits(df.copy(), name='test', seed=seed)\n",
    "  test_size = len(sdf.loc[(sdf['split'] == 'test')])\n",
    "  test_pos = len(sdf.loc[(sdf['split'] == 'test') & (sdf['class_label'] == 1)])\n",
    "  avg_p.append(test_pos/test_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:43:41.371503Z",
     "start_time": "2019-06-17T19:43:41.349497Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_p = np.array(avg_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:43:50.438308Z",
     "start_time": "2019-06-17T19:43:50.417839Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Average prevalence = {(avg_p.mean()):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T19:44:07.665061Z",
     "start_time": "2019-06-17T19:44:07.642882Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Std prevalance = {(avg_p.std()):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T20:54:57.718667Z",
     "start_time": "2019-06-06T20:54:57.677318Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[(df['class_label'] == 0)].groupby('category').apply(lambda g: pd.Series(g['subject_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T20:58:49.439931Z",
     "start_time": "2019-06-06T20:58:49.273675Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[(df['class_label'] == 0)].groupby('category').size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
